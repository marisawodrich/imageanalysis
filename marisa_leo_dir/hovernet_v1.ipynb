{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hovernet_v1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# HoVer-Net re-implementation"
      ],
      "metadata": {
        "id": "fochJKHAdGWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mo8Xm84jP0s",
        "outputId": "3b7f82b3-6094-4002-f278-8fa084eb0555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_files_path = '/content/drive/My Drive/CoNSeP/Train/%s/'\n",
        "test_files_path = '/content/drive/My Drive/CoNSeP/Test/%s/'"
      ],
      "metadata": {
        "id": "fEo-TsMClFor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorpack"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUMaGK9vep8y",
        "outputId": "1d36d461-86bd-401f-f73b-244b4e2d46df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorpack\n",
            "  Downloading tensorpack-0.11-py2.py3-none-any.whl (296 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 17.7 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 30 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 40 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 92 kB 6.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 102 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 112 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 122 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 133 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 143 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 153 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 163 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 174 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 184 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 194 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 204 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 215 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 225 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 235 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 245 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 256 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 266 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 276 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 286 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 296 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.1.0)\n",
            "Requirement already satisfied: pyzmq>=16 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (22.3.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (0.8.9)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.0.3)\n",
            "Requirement already satisfied: numpy>=1.14 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.21.5)\n",
            "Requirement already satisfied: psutil>=5 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (5.4.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorpack) (1.15.0)\n",
            "Collecting msgpack-numpy>=0.4.4.2\n",
            "  Downloading msgpack_numpy-0.4.7.1-py2.py3-none-any.whl (6.7 kB)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from tensorpack) (4.63.0)\n",
            "Installing collected packages: msgpack-numpy, tensorpack\n",
            "Successfully installed msgpack-numpy-0.4.7.1 tensorpack-0.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObFxgjgmdF2e"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorpack import *\n",
        "from tensorpack.models import BatchNorm, BNReLU, Conv2D, MaxPooling, FixedUnPooling\n",
        "from tensorpack.tfutils.summary import add_moving_summary, add_param_summary\n",
        "\n",
        "import sys\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorpack import *\n",
        "from tensorpack.tfutils.symbolic_functions import *\n",
        "from tensorpack.tfutils.summary import *\n",
        "\n",
        "from matplotlib import cm\n",
        "\n",
        "import importlib\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorpack import imgaug\n",
        "\n",
        "import math\n",
        "\n",
        "import cv2\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "\n",
        "from scipy import ndimage\n",
        "from scipy.ndimage import measurements\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "from scipy.ndimage.interpolation import affine_transform, map_coordinates\n",
        "from scipy.ndimage.morphology import (distance_transform_cdt,\n",
        "                                      distance_transform_edt)\n",
        "from skimage import morphology as morph\n",
        "\n",
        "from tensorpack.dataflow.imgaug import ImageAugmentor\n",
        "from tensorpack.utils.utils import get_rng\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorpack import Inferencer, logger\n",
        "from tensorpack.callbacks import (DataParallelInferenceRunner, ModelSaver,\n",
        "                                  MinSaver, MaxSaver, ScheduledHyperParamSetter)\n",
        "from tensorpack.tfutils import SaverRestore, get_model_loader\n",
        "from tensorpack.train import (SyncMultiGPUTrainerParameterServer, TrainConfig,\n",
        "                              launch_train_with_config)\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "misc utils"
      ],
      "metadata": {
        "id": "qDGZlHMLfuY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "####\n",
        "def normalize(mask, dtype=np.uint8):\n",
        "    return (255 * mask / np.amax(mask)).astype(dtype)\n",
        "\n",
        "####\n",
        "def bounding_box(img):\n",
        "    rows = np.any(img, axis=1)\n",
        "    cols = np.any(img, axis=0)\n",
        "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
        "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
        "    # due to python indexing, need to add 1 to max\n",
        "    # else accessing will be 1px in the box, not out \n",
        "    rmax += 1\n",
        "    cmax += 1\n",
        "    return [rmin, rmax, cmin, cmax]\n",
        "\n",
        "####\n",
        "def cropping_center(x, crop_shape, batch=False):   \n",
        "    orig_shape = x.shape\n",
        "    if not batch:\n",
        "        h0 = int((orig_shape[0] - crop_shape[0]) * 0.5)\n",
        "        w0 = int((orig_shape[1] - crop_shape[1]) * 0.5)\n",
        "        x = x[h0:h0 + crop_shape[0], w0:w0 + crop_shape[1]]\n",
        "    else:\n",
        "        h0 = int((orig_shape[1] - crop_shape[0]) * 0.5)\n",
        "        w0 = int((orig_shape[2] - crop_shape[1]) * 0.5)\n",
        "        x = x[:,h0:h0 + crop_shape[0], w0:w0 + crop_shape[1]]        \n",
        "    return x\n",
        "\n",
        "####\n",
        "def rm_n_mkdir(dir_path):\n",
        "    if (os.path.isdir(dir_path)):\n",
        "        shutil.rmtree(dir_path)\n",
        "    os.makedirs(dir_path)\n",
        "\n",
        "####\n",
        "def get_files(data_dir_list, data_ext):\n",
        "    \"\"\"\n",
        "    Given a list of directories containing data with extention 'data_ext',\n",
        "    generate a list of paths for all files within these directories\n",
        "    \"\"\"\n",
        "\n",
        "    data_files = []\n",
        "    for sub_dir in data_dir_list:\n",
        "        files_list = glob.glob(sub_dir + '/*'+ data_ext)\n",
        "        files_list.sort() # ensure same order\n",
        "        data_files.extend(files_list)\n",
        "\n",
        "    return data_files\n",
        "\n",
        "####\n",
        "def get_inst_centroid(inst_map):\n",
        "    inst_centroid_list = []\n",
        "    inst_id_list = list(np.unique(inst_map))\n",
        "    for inst_id in inst_id_list[1:]: # avoid 0 i.e background\n",
        "        mask = np.array(inst_map == inst_id, np.uint8)\n",
        "        inst_moment = cv2.moments(mask)\n",
        "        inst_centroid = [(inst_moment[\"m10\"] / inst_moment[\"m00\"]),\n",
        "                         (inst_moment[\"m01\"] / inst_moment[\"m00\"])]\n",
        "        inst_centroid_list.append(inst_centroid)\n",
        "    return np.array(inst_centroid_list)"
      ],
      "metadata": {
        "id": "wkg9zXpRfwTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loader augs"
      ],
      "metadata": {
        "id": "kUdt04fdfjCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GenInstance(ImageAugmentor):\n",
        "    def __init__(self, crop_shape=None):\n",
        "        super(GenInstance, self).__init__()\n",
        "        self.crop_shape = crop_shape\n",
        "    \n",
        "    def reset_state(self):\n",
        "        self.rng = get_rng(self)\n",
        "\n",
        "    def _fix_mirror_padding(self, ann):\n",
        "        \"\"\"\n",
        "        Deal with duplicated instances due to mirroring in interpolation\n",
        "        during shape augmentation (scale, rotation etc.)\n",
        "        \"\"\"\n",
        "        current_max_id = np.amax(ann)\n",
        "        inst_list = list(np.unique(ann))\n",
        "        inst_list.remove(0) # 0 is background\n",
        "        for inst_id in inst_list:\n",
        "            inst_map = np.array(ann == inst_id, np.uint8)\n",
        "            remapped_ids = measurements.label(inst_map)[0]\n",
        "            remapped_ids[remapped_ids > 1] += current_max_id\n",
        "            ann[remapped_ids > 1] = remapped_ids[remapped_ids > 1]\n",
        "            current_max_id = np.amax(ann)\n",
        "        return ann\n",
        "####\n",
        "import matplotlib.pyplot as plt\n",
        "class GenInstanceUnetMap(GenInstance):\n",
        "    \"\"\"\n",
        "    Input annotation must be of original shape.\n",
        "    Perform following operation:\n",
        "        1) Remove the 1px of boundary of each instance\n",
        "           to create separation between touching instances\n",
        "        2) Generate the weight map from the result of 1)\n",
        "           according to the unet paper equation.\n",
        "    Args:\n",
        "        wc (dict)        : Dictionary of weight classes.\n",
        "        w0 (int/float)   : Border weight parameter.\n",
        "        sigma (int/float): Border width parameter.\n",
        "    \"\"\"\n",
        "    def __init__(self, wc=None, w0=10.0, sigma=5.0, crop_shape=None):\n",
        "        super(GenInstanceUnetMap, self).__init__()\n",
        "        self.crop_shape = crop_shape\n",
        "        self.wc = wc\n",
        "        self.w0 = w0\n",
        "        self.sigma = sigma\n",
        "\n",
        "    def _remove_1px_boundary(self, ann):\n",
        "        new_ann = np.zeros(ann.shape[:2], np.int32)\n",
        "        inst_list = list(np.unique(ann))\n",
        "        inst_list.remove(0) # 0 is background\n",
        "\n",
        "        k = np.array([[0, 1, 0],\n",
        "                      [1, 1, 1],\n",
        "                      [0, 1, 0]], np.uint8)\n",
        "\n",
        "        for idx, inst_id in enumerate(inst_list):\n",
        "            inst_map = np.array(ann == inst_id, np.uint8)\n",
        "            inst_map = cv2.erode(inst_map, k, iterations=1)\n",
        "            new_ann[inst_map > 0] = inst_id\n",
        "        return new_ann\n",
        "\n",
        "    def _get_weight_map(self, ann, inst_list):\n",
        "        if len(inst_list) <= 1: # 1 instance only\n",
        "            return np.zeros(ann.shape[:2])\n",
        "        stacked_inst_bgd_dst = np.zeros(ann.shape[:2] +(len(inst_list),))\n",
        "\n",
        "        for idx, inst_id in enumerate(inst_list):\n",
        "            inst_bgd_map = np.array(ann != inst_id , np.uint8)\n",
        "            inst_bgd_dst = distance_transform_edt(inst_bgd_map)\n",
        "            stacked_inst_bgd_dst[...,idx] = inst_bgd_dst\n",
        "\n",
        "        near1_dst = np.amin(stacked_inst_bgd_dst, axis=2)\n",
        "        near2_dst = np.expand_dims(near1_dst ,axis=2)\n",
        "        near2_dst = stacked_inst_bgd_dst - near2_dst\n",
        "        near2_dst[near2_dst == 0] = np.PINF # very large\n",
        "        near2_dst = np.amin(near2_dst, axis=2)\n",
        "        near2_dst[ann > 0] = 0 # the instances\n",
        "        near2_dst = near2_dst + near1_dst\n",
        "        # to fix pixel where near1 == near2\n",
        "        near2_eve = np.expand_dims(near1_dst ,axis=2)\n",
        "        # to avoide the warning of a / 0\n",
        "        near2_eve = (1.0 + stacked_inst_bgd_dst) / (1.0 + near2_eve)\n",
        "        near2_eve[near2_eve != 1] = 0\n",
        "        near2_eve = np.sum(near2_eve, axis=2)\n",
        "        near2_dst[near2_eve > 1] = near1_dst[near2_eve > 1]\n",
        "        #\n",
        "        pix_dst = near1_dst + near2_dst\n",
        "        pen_map = pix_dst / self.sigma\n",
        "        pen_map = self.w0 * np.exp(- pen_map**2 / 2)\n",
        "        pen_map[ann > 0] = 0 # inner instances zero\n",
        "        return pen_map\n",
        "\n",
        "    def _augment(self, img, _):\n",
        "        img = np.copy(img)\n",
        "        orig_ann = img[...,0] # instance ID map\n",
        "        fixed_ann = self._fix_mirror_padding(orig_ann)\n",
        "        # setting 1 boundary pix of each instance to background\n",
        "        fixed_ann = self._remove_1px_boundary(fixed_ann)\n",
        "\n",
        "        # cant do the shortcut because near2 also needs instances \n",
        "        # outside of cropped portion\n",
        "        inst_list = list(np.unique(fixed_ann))\n",
        "        inst_list.remove(0) # 0 is background\n",
        "        wmap = self._get_weight_map(fixed_ann, inst_list)\n",
        "\n",
        "        if self.wc is None:             \n",
        "            wmap += 1 # uniform weight for all classes\n",
        "        else:\n",
        "            class_weights = np.zeros_like(fixed_ann.shape[:2])\n",
        "            for class_id, class_w in self.wc.items():\n",
        "                class_weights[fixed_ann == class_id] = class_w\n",
        "            wmap += class_weights\n",
        "\n",
        "        # fix other maps to align\n",
        "        img[fixed_ann == 0] = 0 \n",
        "        img = np.dstack([img, wmap])\n",
        "\n",
        "        return img\n",
        "\n",
        "####\n",
        "class GenInstanceContourMap(GenInstance):\n",
        "    \"\"\"\n",
        "    Input annotation must be of original shape.\n",
        "    \n",
        "    Perform following operation:\n",
        "        1) Dilate each instance by a kernel with \n",
        "           a diameter of 7 pix.\n",
        "        2) Erode each instance by a kernel with \n",
        "           a diameter of 7 pix.\n",
        "        3) Obtain the contour by subtracting the \n",
        "           eroded instance from the dilated instance.\n",
        "    \n",
        "    \"\"\"\n",
        "    def __init__(self, crop_shape=None):\n",
        "        super(GenInstanceContourMap, self).__init__()\n",
        "        self.crop_shape = crop_shape\n",
        "\n",
        "    def _augment(self, img, _):\n",
        "        img = np.copy(img)\n",
        "        orig_ann = img[...,0] # instance ID map\n",
        "        fixed_ann = self._fix_mirror_padding(orig_ann)\n",
        "            # re-cropping with fixed instance id map\n",
        "        crop_ann = cropping_center(fixed_ann, self.crop_shape)\n",
        "\n",
        "        # setting 1 boundary pix of each instance to background\n",
        "        contour_map = np.zeros(fixed_ann.shape[:2], np.uint8)\n",
        "\n",
        "        inst_list = list(np.unique(crop_ann))\n",
        "        inst_list.remove(0) # 0 is background\n",
        "\n",
        "        k_disk = np.array([\n",
        "            [0, 0, 0, 1, 0, 0, 0],\n",
        "            [0, 0, 1, 1, 1, 0, 0],\n",
        "            [0, 1, 1, 1, 1, 1, 0],\n",
        "            [1, 1, 1, 1, 1, 1, 1],\n",
        "            [0, 1, 1, 1, 1, 1, 0],\n",
        "            [0, 0, 1, 1, 1, 0, 0],\n",
        "            [0, 0, 0, 1, 0, 0, 0],\n",
        "        ], np.uint8)\n",
        "\n",
        "        for inst_id in inst_list:\n",
        "            inst_map = np.array(fixed_ann == inst_id, np.uint8)\n",
        "            inner = cv2.erode(inst_map, k_disk, iterations=1)\n",
        "            outer = cv2.dilate(inst_map, k_disk, iterations=1)\n",
        "            contour_map += outer - inner\n",
        "        contour_map[contour_map > 0] = 1 # binarize\n",
        "        img = np.dstack([fixed_ann, contour_map])\n",
        "        return img\n",
        "\n",
        "####\n",
        "class GenInstanceHV(GenInstance):   \n",
        "    \"\"\"\n",
        "        Input annotation must be of original shape.\n",
        "        \n",
        "        The map is calculated only for instances within the crop portion\n",
        "        but based on the original shape in original image.\n",
        "    \n",
        "        Perform following operation:\n",
        "        Obtain the horizontal and vertical distance maps for each\n",
        "        nuclear instance.\n",
        "    \"\"\"\n",
        "\n",
        "    def _augment(self, img, _):\n",
        "        img = np.copy(img)\n",
        "        orig_ann = img[...,0] # instance ID map\n",
        "        fixed_ann = self._fix_mirror_padding(orig_ann)\n",
        "        # re-cropping with fixed instance id map\n",
        "        crop_ann = cropping_center(fixed_ann, self.crop_shape)\n",
        "        # TODO: deal with 1 label warning\n",
        "        crop_ann = morph.remove_small_objects(crop_ann, min_size=30)\n",
        "\n",
        "        x_map = np.zeros(orig_ann.shape[:2], dtype=np.float32)\n",
        "        y_map = np.zeros(orig_ann.shape[:2], dtype=np.float32)\n",
        "\n",
        "        inst_list = list(np.unique(crop_ann))\n",
        "        inst_list.remove(0) # 0 is background\n",
        "        for inst_id in inst_list:\n",
        "            inst_map = np.array(fixed_ann == inst_id, np.uint8)\n",
        "            inst_box = bounding_box(inst_map)\n",
        "\n",
        "            # expand the box by 2px\n",
        "            # Because we first pad the ann at line 207, the bboxes\n",
        "            # will remain valid after expansion\n",
        "            inst_box[0] -= 2\n",
        "            inst_box[2] -= 2\n",
        "            inst_box[1] += 2\n",
        "            inst_box[3] += 2\n",
        "\n",
        "            inst_map = inst_map[inst_box[0]:inst_box[1],\n",
        "                                inst_box[2]:inst_box[3]]\n",
        "\n",
        "            if inst_map.shape[0] < 2 or \\\n",
        "                inst_map.shape[1] < 2:\n",
        "                continue\n",
        "\n",
        "            # instance center of mass, rounded to nearest pixel\n",
        "            inst_com = list(measurements.center_of_mass(inst_map))\n",
        "            \n",
        "            inst_com[0] = int(inst_com[0] + 0.5)\n",
        "            inst_com[1] = int(inst_com[1] + 0.5)\n",
        "\n",
        "            inst_x_range = np.arange(1, inst_map.shape[1]+1)\n",
        "            inst_y_range = np.arange(1, inst_map.shape[0]+1)\n",
        "            # shifting center of pixels grid to instance center of mass\n",
        "            inst_x_range -= inst_com[1]\n",
        "            inst_y_range -= inst_com[0]\n",
        "            \n",
        "            inst_x, inst_y = np.meshgrid(inst_x_range, inst_y_range)\n",
        "\n",
        "            # remove coord outside of instance\n",
        "            inst_x[inst_map == 0] = 0\n",
        "            inst_y[inst_map == 0] = 0\n",
        "            inst_x = inst_x.astype('float32')\n",
        "            inst_y = inst_y.astype('float32')\n",
        "\n",
        "            # normalize min into -1 scale\n",
        "            if np.min(inst_x) < 0:\n",
        "                inst_x[inst_x < 0] /= (-np.amin(inst_x[inst_x < 0]))\n",
        "            if np.min(inst_y) < 0:\n",
        "                inst_y[inst_y < 0] /= (-np.amin(inst_y[inst_y < 0]))\n",
        "            # normalize max into +1 scale\n",
        "            if np.max(inst_x) > 0:\n",
        "                inst_x[inst_x > 0] /= (np.amax(inst_x[inst_x > 0]))\n",
        "            if np.max(inst_y) > 0:\n",
        "                inst_y[inst_y > 0] /= (np.amax(inst_y[inst_y > 0]))\n",
        "\n",
        "            ####\n",
        "            x_map_box = x_map[inst_box[0]:inst_box[1],\n",
        "                              inst_box[2]:inst_box[3]]\n",
        "            x_map_box[inst_map > 0] = inst_x[inst_map > 0]\n",
        "\n",
        "            y_map_box = y_map[inst_box[0]:inst_box[1],\n",
        "                              inst_box[2]:inst_box[3]]\n",
        "            y_map_box[inst_map > 0] = inst_y[inst_map > 0]\n",
        "\n",
        "        img = img.astype('float32')\n",
        "        img = np.dstack([img, x_map, y_map])\n",
        "\n",
        "        return img\n",
        "\n",
        "####\n",
        "class GenInstanceDistance(GenInstance):   \n",
        "    \"\"\"\n",
        "    Input annotation must be of original shape.\n",
        "    \n",
        "    The map is calculated only for instances within the crop portion\n",
        "    but based on the original shape in original image.\n",
        "    \n",
        "    Perform following operation:\n",
        "    Obtain the standard distance map of nuclear pixels to their closest\n",
        "    boundary.\n",
        "    Can be interpreted as the inverse distance map of nuclear pixels to \n",
        "    the centroid. \n",
        "    \"\"\"\n",
        "    def __init__(self, crop_shape=None, inst_norm=True):\n",
        "        super(GenInstanceDistance, self).__init__()\n",
        "        self.crop_shape = crop_shape\n",
        "        self.inst_norm = inst_norm\n",
        "\n",
        "    def _augment(self, img, _):\n",
        "        img = np.copy(img)\n",
        "        orig_ann = img[...,0] # instance ID map\n",
        "        fixed_ann = self._fix_mirror_padding(orig_ann)\n",
        "        # re-cropping with fixed instance id map\n",
        "        crop_ann = cropping_center(fixed_ann, self.crop_shape)\n",
        "\n",
        "        orig_dst = np.zeros(orig_ann.shape, dtype=np.float32)  \n",
        "\n",
        "        inst_list = list(np.unique(crop_ann))\n",
        "        inst_list.remove(0) # 0 is background\n",
        "        for inst_id in inst_list:\n",
        "            inst_map = np.array(fixed_ann == inst_id, np.uint8)\n",
        "            inst_box = bounding_box(inst_map)\n",
        "\n",
        "            # expand the box by 2px\n",
        "            inst_box[0] -= 2\n",
        "            inst_box[2] -= 2\n",
        "            inst_box[1] += 2\n",
        "            inst_box[3] += 2\n",
        "\n",
        "            inst_map = inst_map[inst_box[0]:inst_box[1],\n",
        "                                inst_box[2]:inst_box[3]]\n",
        "\n",
        "            if inst_map.shape[0] < 2 or \\\n",
        "                inst_map.shape[1] < 2:\n",
        "                continue\n",
        "\n",
        "            # chessboard distance map generation\n",
        "            # normalize distance to 0-1\n",
        "            inst_dst = distance_transform_cdt(inst_map)\n",
        "            inst_dst = inst_dst.astype('float32')\n",
        "            if self.inst_norm:\n",
        "                max_value = np.amax(inst_dst)\n",
        "                if max_value <= 0: \n",
        "                    continue # HACK: temporay patch for divide 0 i.e no nuclei (how?)\n",
        "                inst_dst = (inst_dst / np.amax(inst_dst)) \n",
        "\n",
        "            ####\n",
        "            dst_map_box = orig_dst[inst_box[0]:inst_box[1],\n",
        "                                   inst_box[2]:inst_box[3]]\n",
        "            dst_map_box[inst_map > 0] = inst_dst[inst_map > 0]\n",
        "\n",
        "        #\n",
        "        img = img.astype('float32')\n",
        "        img = np.dstack([img, orig_dst])\n",
        "        \n",
        "        return img\n",
        "\n",
        "####\n",
        "class GaussianBlur(ImageAugmentor):\n",
        "    \"\"\" Gaussian blur the image with random window size\"\"\"\n",
        "    def __init__(self, max_size=3):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            max_size (int): max possible Gaussian window size would be 2 * max_size + 1\n",
        "        \"\"\"\n",
        "        super(GaussianBlur, self).__init__()\n",
        "        self.max_size = max_size\n",
        "\n",
        "    def _get_augment_params(self, img):\n",
        "        sx, sy = self.rng.randint(1, self.max_size, size=(2,))\n",
        "        sx = sx * 2 + 1\n",
        "        sy = sy * 2 + 1\n",
        "        return sx, sy\n",
        "\n",
        "    def _augment(self, img, s):\n",
        "        return np.reshape(cv2.GaussianBlur(img, s, sigmaX=0, sigmaY=0,\n",
        "                                           borderType=cv2.BORDER_REPLICATE), img.shape)\n",
        "\n",
        "####\n",
        "class BinarizeLabel(ImageAugmentor):\n",
        "    \"\"\" Convert labels to binary maps\"\"\"\n",
        "    def __init__(self):\n",
        "        super(BinarizeLabel, self).__init__()\n",
        "\n",
        "    def _get_augment_params(self, img):\n",
        "        return None\n",
        "\n",
        "    def _augment(self, img, s):\n",
        "        img = np.copy(img)\n",
        "        arr = img[...,0]\n",
        "        arr[arr > 0] = 1\n",
        "        return img\n",
        "\n",
        "####\n",
        "class MedianBlur(ImageAugmentor):\n",
        "    \"\"\" Median blur the image with random window size\"\"\"\n",
        "    def __init__(self, max_size=3):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            max_size (int): max possible window size \n",
        "                            would be 2 * max_size + 1\n",
        "        \"\"\"\n",
        "        super(MedianBlur, self).__init__()\n",
        "        self.max_size = max_size\n",
        "\n",
        "    def _get_augment_params(self, img):\n",
        "        s = self.rng.randint(1, self.max_size)\n",
        "        s = s * 2 + 1\n",
        "        return s\n",
        "\n",
        "    def _augment(self, img, ksize):\n",
        "        return cv2.medianBlur(img, ksize)"
      ],
      "metadata": {
        "id": "h4s5925OflW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some utils:"
      ],
      "metadata": {
        "id": "9RSzqDh8fOMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_op(x, height_factor=None, width_factor=None, size=None, \n",
        "                interp='bicubic', data_format='channels_last'):\n",
        "    \"\"\"\n",
        "    Resize by a factor if `size=None` else resize to `size`\n",
        "    \"\"\"\n",
        "    original_shape = x.get_shape().as_list()\n",
        "    if size is not None:\n",
        "        if data_format == 'channels_first':\n",
        "            x = tf.transpose(x, [0, 2, 3, 1])\n",
        "            if interp == 'bicubic':\n",
        "                x = tf.image.resize_bicubic(x, size)\n",
        "            elif interp == 'bilinear':\n",
        "                x = tf.image.resize_bilinear(x, size)\n",
        "            else:\n",
        "                x = tf.image.resize_nearest_neighbor(x, size)\n",
        "            x = tf.transpose(x, [0, 3, 1, 2])\n",
        "            x.set_shape((None, \n",
        "                original_shape[1] if original_shape[1] is not None else None, \n",
        "                size[0], size[1]))\n",
        "        else:\n",
        "            if interp == 'bicubic':\n",
        "                x = tf.image.resize_bicubic(x, size)\n",
        "            elif interp == 'bilinear':\n",
        "                x = tf.image.resize_bilinear(x, size)\n",
        "            else:\n",
        "                x = tf.image.resize_nearest_neighbor(x, size)\n",
        "            x.set_shape((None, \n",
        "                size[0], size[1], \n",
        "                original_shape[3] if original_shape[3] is not None else None))\n",
        "    else:\n",
        "        if data_format == 'channels_first':\n",
        "            new_shape = tf.cast(tf.shape(x)[2:], tf.float32)    \n",
        "            new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('float32'))\n",
        "            new_shape = tf.cast(new_shape, tf.int32)    \n",
        "            x = tf.transpose(x, [0, 2, 3, 1])\n",
        "            if interp == 'bicubic':\n",
        "                x = tf.image.resize_bicubic(x, new_shape)\n",
        "            elif interp == 'bilinear':\n",
        "                x = tf.image.resize_bilinear(x, new_shape)\n",
        "            else:\n",
        "                x = tf.image.resize_nearest_neighbor(x, new_shape)\n",
        "            x = tf.transpose(x, [0, 3, 1, 2])\n",
        "            x.set_shape((None,\n",
        "                        original_shape[1] if original_shape[1] is not None else None,\n",
        "                        int(original_shape[2] * height_factor) if original_shape[2] is not None else None,\n",
        "                        int(original_shape[3] * width_factor) if original_shape[3] is not None else None))\n",
        "        else:\n",
        "            original_shape = x.get_shape().as_list()\n",
        "            new_shape = tf.cast(tf.shape(x)[1:3], tf.float32)    \n",
        "            new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('float32'))\n",
        "            new_shape = tf.cast(new_shape, tf.int32)    \n",
        "            if interp == 'bicubic':\n",
        "                x = tf.image.resize_bicubic(x, new_shape)\n",
        "            elif interp == 'bilinear':\n",
        "                x = tf.image.resize_bilinear(x, new_shape)\n",
        "            else:\n",
        "                x = tf.image.resize_nearest_neighbor(x, new_shape)\n",
        "            x.set_shape((None,\n",
        "                        int(original_shape[1] * height_factor) if original_shape[1] is not None else None,\n",
        "                        int(original_shape[2] * width_factor) if original_shape[2] is not None else None,\n",
        "                        original_shape[3] if original_shape[3] is not None else None))\n",
        "    return x \n",
        "\n",
        "####\n",
        "def crop_op(x, cropping, data_format='channels_first'):\n",
        "    \"\"\"\n",
        "    Center crop image\n",
        "    Args:\n",
        "        cropping is the substracted portion\n",
        "    \"\"\"\n",
        "    crop_t = cropping[0] // 2\n",
        "    crop_b = cropping[0] - crop_t\n",
        "    crop_l = cropping[1] // 2\n",
        "    crop_r = cropping[1] - crop_l\n",
        "    if data_format == 'channels_first':\n",
        "        x = x[:,:,crop_t:-crop_b,crop_l:-crop_r]\n",
        "    else:\n",
        "        x = x[:,crop_t:-crop_b,crop_l:-crop_r]\n",
        "    return x       \n",
        "####\n",
        "\n",
        "def categorical_crossentropy(output, target):\n",
        "    \"\"\"\n",
        "        categorical cross-entropy, accept probabilities not logit\n",
        "    \"\"\"\n",
        "    # scale preds so that the class probs of each sample sum to 1\n",
        "    output /= tf.reduce_sum(output,\n",
        "                            reduction_indices=len(output.get_shape()) - 1,\n",
        "                            keepdims=True)\n",
        "    # manual computation of crossentropy\n",
        "    epsilon = tf.convert_to_tensor(10e-8, output.dtype.base_dtype)\n",
        "    output = tf.clip_by_value(output, epsilon, 1. - epsilon)\n",
        "    return - tf.reduce_sum(target * tf.log(output),\n",
        "                            reduction_indices=len(output.get_shape()) - 1)\n",
        "####\n",
        "def dice_loss(output, target, loss_type='sorensen', axis=None, smooth=1e-3):\n",
        "    \"\"\"Soft dice (Sørensen or Jaccard) coefficient for comparing the similarity\n",
        "    of two batch of data, usually be used for binary image segmentation\n",
        "    i.e. labels are binary. The coefficient between 0 to 1, 1 means totally match.\n",
        "    Parameters\n",
        "    -----------\n",
        "    output : Tensor\n",
        "        A distribution with shape: [batch_size, ....], (any dimensions).\n",
        "    target : Tensor\n",
        "        The target distribution, format the same with `output`.\n",
        "    loss_type : str\n",
        "        ``jaccard`` or ``sorensen``, default is ``jaccard``.\n",
        "    axis : tuple of int\n",
        "        All dimensions are reduced, default ``[1,2,3]``.\n",
        "    smooth : float\n",
        "        This small value will be added to the numerator and denominator.\n",
        "            - If both output and target are empty, it makes sure dice is 1.\n",
        "            - If either output or target are empty (all pixels are background), \n",
        "              dice = ```smooth/(small_value + smooth)``, then if smooth is very small, \n",
        "              dice close to 0 (even the image values lower than the threshold), \n",
        "              so in this case, higher smooth can have a higher dice.\n",
        "    Examples\n",
        "    ---------\n",
        "    >>> dice_loss = dice_coe(outputs, y_)\n",
        "    \"\"\"\n",
        "    target = tf.squeeze(tf.cast(target, tf.float32))\n",
        "    output = tf.squeeze(tf.cast(output, tf.float32))\n",
        "\n",
        "    inse = tf.reduce_sum(output * target, axis=axis)\n",
        "    if loss_type == 'jaccard':\n",
        "        l = tf.reduce_sum(output * output, axis=axis)\n",
        "        r = tf.reduce_sum(target * target, axis=axis)\n",
        "    elif loss_type == 'sorensen':\n",
        "        l = tf.reduce_sum(output, axis=axis)\n",
        "        r = tf.reduce_sum(target, axis=axis)\n",
        "    else:\n",
        "        raise Exception(\"Unknown loss_type\")\n",
        "    # already flatten\n",
        "    dice = 1.0 - (2. * inse + smooth) / (l + r + smooth)\n",
        "    ##\n",
        "    return dice\n",
        "####\n",
        "def colorize(value, vmin=None, vmax=None, cmap=None):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "      - value: input tensor, NHWC ('channels_last')\n",
        "      - vmin: the minimum value of the range used for normalization.\n",
        "        (Default: value minimum)\n",
        "      - vmax: the maximum value of the range used for normalization.\n",
        "        (Default: value maximum)\n",
        "      - cmap: a valid cmap named for use with matplotlib's `get_cmap`.\n",
        "        (Default: 'gray')\n",
        "    Example usage:\n",
        "    ```\n",
        "    output = tf.random_uniform(shape=[256, 256, 1])\n",
        "    output_color = colorize(output, vmin=0.0, vmax=1.0, cmap='viridis')\n",
        "    tf.summary.image('output', output_color)\n",
        "    ```\n",
        "    \n",
        "    Returns a 3D tensor of shape [height, width, 3], uint8.\n",
        "    \"\"\"\n",
        "\n",
        "    # normalize\n",
        "    if vmin is None:\n",
        "        vmin = tf.reduce_min(value, axis=[1,2])\n",
        "        vmin = tf.reshape(vmin, [-1, 1, 1])\n",
        "    if vmax is None:\n",
        "        vmax = tf.reduce_max(value, axis=[1,2])\n",
        "        vmax = tf.reshape(vmax, [-1, 1, 1])\n",
        "    value = (value - vmin) / (vmax - vmin) # vmin..vmax\n",
        "\n",
        "    # squeeze last dim if it exists\n",
        "    # NOTE: will throw error if use get_shape()\n",
        "    # value = tf.squeeze(value)\n",
        "\n",
        "    # quantize\n",
        "    value = tf.round(value * 255)\n",
        "    indices = tf.cast(value, np.int32)\n",
        "\n",
        "    # gather\n",
        "    colormap = cm.get_cmap(cmap if cmap is not None else 'gray')\n",
        "    colors = colormap(np.arange(256))[:, :3]\n",
        "    colors = tf.constant(colors, dtype=tf.float32)\n",
        "    value = tf.gather(colors, indices)\n",
        "    value = tf.cast(value * 255, tf.uint8)\n",
        "    return value\n",
        "####\n",
        "def make_image(x, cy, cx, scale_y, scale_x):\n",
        "    \"\"\"\n",
        "    Take 1st image from x and turn channels representations\n",
        "    into 2D image, with cx number of channels in x-axis and\n",
        "    cy number of channels in y-axis\n",
        "    \"\"\"\n",
        "    # norm x for better visual\n",
        "    x = tf.transpose(x,(0,2,3,1)) # NHWC\n",
        "    max_x = tf.reduce_max(x, axis=-1, keep_dims=True)\n",
        "    min_x = tf.reduce_min(x, axis=-1, keep_dims=True)\n",
        "    x = 255 * (x - min_x) / (max_x - min_x)\n",
        "    ###\n",
        "    x_shape = tf.shape(x)\n",
        "    channels = x_shape[-1]\n",
        "    iy , ix = x_shape[1], x_shape[2] \n",
        "    ###\n",
        "    x = tf.slice(x,(0,0,0,0),(1,-1,-1,-1))\n",
        "    x = tf.reshape(x,(iy,ix,channels))\n",
        "    ix += 4\n",
        "    iy += 4\n",
        "    x = tf.image.resize_image_with_crop_or_pad(x, iy, ix)\n",
        "    x = tf.reshape(x,(iy,ix,cy,cx)) \n",
        "    x = tf.transpose(x,(2,0,3,1)) #cy,iy,cx,ix\n",
        "    x = tf.reshape(x,(1,cy*iy,cx*ix,1))\n",
        "    x = resize_op(x, scale_y, scale_x)\n",
        "    return tf.cast(x, tf.uint8)"
      ],
      "metadata": {
        "id": "DCLRUXbxe9Ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "opt.hover"
      ],
      "metadata": {
        "id": "pJDMpDeAo6xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "config_dict = { #called np_hv before\n",
        "    'train_input_shape' : [270, 270],\n",
        "    'train_mask_shape'  : [ 80,  80],\n",
        "    'infer_input_shape' : [270, 270],\n",
        "    'infer_mask_shape'  : [ 80,  80], \n",
        "\n",
        "    'training_phase'    : [\n",
        "        {\n",
        "            'nr_epochs': 50,\n",
        "            'manual_parameters' : { \n",
        "                # tuple(initial value, schedule)\n",
        "                'learning_rate': (1.0e-4, [('25', 1.0e-5)]), \n",
        "            },\n",
        "            'pretrained_path'  : '../../../pretrained/ImageNet-ResNet50-Preact.npz',\n",
        "            'train_batch_size' : 8,\n",
        "            'infer_batch_size' : 16,\n",
        "\n",
        "            'model_flags' : {\n",
        "                'freeze' : True\n",
        "            }\n",
        "        },\n",
        "\n",
        "        {\n",
        "            'nr_epochs': 50,\n",
        "            'manual_parameters' : { \n",
        "                # tuple(initial value, schedule)\n",
        "                'learning_rate': (1.0e-4, [('25', 1.0e-5)]), \n",
        "            },\n",
        "            # path to load, -1 to auto load checkpoint from previous phase, \n",
        "            # None to start from scratch\n",
        "            'pretrained_path'  : -1,\n",
        "            'train_batch_size' : 4, # unfreezing everything will\n",
        "            'infer_batch_size' : 16,\n",
        "\n",
        "            'model_flags' : {\n",
        "                'freeze' : False\n",
        "            }\n",
        "        }\n",
        "    ],\n",
        "\n",
        "  \n",
        "\n",
        "    'loss_term' : {'bce' : 1, 'dice' : 1, 'mse' : 2, 'msge' : 1}, \n",
        "\n",
        "    'optimizer'           : tf.keras.optimizers.Adam\n",
        ",\n",
        "\n",
        "    'inf_auto_metric'   : 'valid_dice',\n",
        "    'inf_auto_comparator' : '>',\n",
        "    'inf_batch_size' : 16,\n",
        "}\n",
        "\n",
        "np_dist = {\n",
        "    'train_input_shape' : [270, 270],\n",
        "    'train_mask_shape'  : [ 80,  80],\n",
        "    'infer_input_shape' : [270, 270],\n",
        "    'infer_mask_shape'  : [ 80,  80], \n",
        "\n",
        "    'training_phase'    : [\n",
        "        {\n",
        "            'nr_epochs': 50,\n",
        "            'manual_parameters' : { \n",
        "                # tuple(initial value, schedule)\n",
        "                'learning_rate': (1.0e-4, [('25', 1.0e-5)]), \n",
        "            },\n",
        "            'pretrained_path'  : '../../../pretrained/ImageNet-ResNet50-Preact.npz',\n",
        "            'train_batch_size' : 8,\n",
        "            'infer_batch_size' : 16,\n",
        "\n",
        "            'model_flags' : {\n",
        "                'freeze' : True\n",
        "            }\n",
        "        },\n",
        "\n",
        "        {\n",
        "            'nr_epochs': 50,\n",
        "            'manual_parameters' : { \n",
        "                # tuple(initial value, schedule)\n",
        "                'learning_rate': (1.0e-4, [('25', 1.0e-5)]), \n",
        "            },\n",
        "            # path to load, -1 to auto load checkpoint from previous phase, \n",
        "            # None to start from scratch\n",
        "            'pretrained_path'  : -1,\n",
        "            'train_batch_size' : 4, # unfreezing everything will\n",
        "            'infer_batch_size' : 16,\n",
        "\n",
        "            'model_flags' : {\n",
        "                'freeze' : False\n",
        "            }\n",
        "        }\n",
        "    ],\n",
        "  \n",
        "    'optimizer'         : tf.compat.v1.train.AdamOptimizer,\n",
        "\n",
        "    'inf_auto_metric'   : 'valid_dice',\n",
        "    'inf_auto_comparator' : '>',\n",
        "    'inf_batch_size' : 16,\n",
        "}\n"
      ],
      "metadata": {
        "id": "x0UFQxXco6J2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loader.loader"
      ],
      "metadata": {
        "id": "KNo2u3f9nd8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetSerial(RNGDataFlow):\n",
        "    \"\"\"\n",
        "    Produce ``(image, label)`` pair, where \n",
        "        ``image`` has shape HWC and is RGB, has values in range [0-255].    \n",
        "        ``label`` is a float image of shape (H, W, C). Number of C depends\n",
        "                  on `self.model_mode` within `config.py`\n",
        "                  If self.model_mode is 'np+xy': \n",
        "                    channel 0 binary nuclei map, values are either 0 (background) or 1 (nuclei)\n",
        "                    channel 1 containing the X-map, values in range [-1, 1]\n",
        "                    channel 2 containing the Y-map, values in range [-1, 1]\n",
        "                  If self.model_mode is 'np+dst': \n",
        "                    channel 0 binary nuclei map, values are either 0 (background) or 1 (nuclei)\n",
        "                    channel 1 containing the per nuclei distance map, values in range [0, 1]\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, path_list):\n",
        "        self.path_list = path_list\n",
        "    ##\n",
        "    def size(self):\n",
        "        return len(self.path_list)\n",
        "    ##\n",
        "    def get_data(self):\n",
        "        idx_list = list(range(0, len(self.path_list)))\n",
        "        random.shuffle(idx_list)\n",
        "        for idx in idx_list:\n",
        "\n",
        "            data = np.load(self.path_list[idx])\n",
        "\n",
        "            # split stacked channel into image and label\n",
        "            img = data[...,:3] # RGB images\n",
        "            ann = data[...,3:] # instance ID map\n",
        "            # TODO: assert to ensure correct dtype\n",
        "            \n",
        "            img = img.astype('uint8')     \n",
        "            yield [img, ann]\n",
        "\n",
        "#### \n",
        "def valid_generator(ds, shape_aug=None, input_aug=None, label_aug=None, batch_size=16, nr_procs=1):\n",
        "    ### augment both the input and label\n",
        "    ds = ds if shape_aug is None else AugmentImageComponents(ds, shape_aug, (0, 1), copy=True)\n",
        "    ### augment just the input\n",
        "    ds = ds if input_aug is None else AugmentImageComponent(ds, input_aug, index=0, copy=False)\n",
        "    ### augment just the output\n",
        "    ds = ds if label_aug is None else AugmentImageComponent(ds, label_aug, index=1, copy=True)\n",
        "    #\n",
        "    ds = BatchData(ds, batch_size, remainder=True)\n",
        "    ds = CacheData(ds) # cache all inference images \n",
        "    return ds\n",
        "\n",
        "####\n",
        "def train_generator(ds, shape_aug=None, input_aug=None, label_aug=None, batch_size=16, nr_procs=8):\n",
        "    ### augment both the input and label\n",
        "    ds = ds if shape_aug is None else AugmentImageComponents(ds, shape_aug, (0, 1), copy=True)\n",
        "    ### augment just the input i.e index 0 within each yield of DatasetSerial\n",
        "    ds = ds if input_aug is None else AugmentImageComponent(ds, input_aug, index=0, copy=False)\n",
        "    ### augment just the output i.e index 1 within each yield of DatasetSerial\n",
        "    ds = ds if label_aug is None else AugmentImageComponent(ds, label_aug, index=1, copy=True)\n",
        "    #\n",
        "    ds = BatchDataByShape(ds, batch_size, idx=0)\n",
        "    ds = PrefetchDataZMQ(ds, nr_procs)\n",
        "    return ds\n",
        "\n",
        "#### \n",
        "def visualize(datagen, batch_size, view_size=4):\n",
        "    \"\"\"\n",
        "    Read the batch from 'datagen' and display 'view_size' number of\n",
        "    of images and their corresponding Ground Truth\n",
        "    \"\"\"\n",
        "    def prep_imgs(img, ann):\n",
        "        cmap = plt.get_cmap('viridis')\n",
        "        # cmap may randomly fails if of other types\n",
        "        ann = ann.astype('float32')\n",
        "        ann_chs = np.dsplit(ann, ann.shape[-1])\n",
        "        for i, ch in enumerate(ann_chs):\n",
        "            ch = np.squeeze(ch)\n",
        "            # normalize to -1 to 1 range else\n",
        "            # cmap may behave stupidly\n",
        "            ch = ch / (np.max(ch) - np.min(ch) + 1.0e-16)\n",
        "            # take RGB from RGBA heat map\n",
        "            ann_chs[i] = cmap(ch)[...,:3]\n",
        "        img = img.astype('float32') / 255.0\n",
        "        prepped_img = np.concatenate([img] + ann_chs, axis=1)\n",
        "        return prepped_img\n",
        "\n",
        "    assert view_size <= batch_size, 'Number of displayed images must <= batch size'\n",
        "    ds = RepeatedData(datagen, -1)    \n",
        "    ds.reset_state()\n",
        "    for imgs, segs in ds.get_data():\n",
        "        for idx in range (0, view_size):\n",
        "            displayed_img = prep_imgs(imgs[idx], segs[idx])\n",
        "            plt.subplot(view_size, 1, idx+1)\n",
        "            plt.imshow(displayed_img)\n",
        "        plt.show()\n",
        "    return"
      ],
      "metadata": {
        "id": "RIW71lg1ndRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "config"
      ],
      "metadata": {
        "id": "a-HiYUlggrPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config(object):\n",
        "    def __init__(self, ):\n",
        "\n",
        "        self.seed = 10 \n",
        "        mode = 'hover'\n",
        "        self.model_type = 'np_hv'\n",
        "\n",
        "        self.type_classification = True # whether to predict the nuclear type\n",
        "        # ! must use CoNSeP dataset, where nuclear type labels are available\n",
        "        # denotes number of classes for nuclear type classification, \n",
        "        # plus the background class\n",
        "        self.nr_types = 5\n",
        "        # ! some semantic segmentation network like micronet,\n",
        "        # ! nr_types will replace nr_classes if type_classification=True\n",
        "        self.nr_classes = 2 # Nuclei Pixels vs Background\n",
        "\n",
        "        # define your nuclei type name here, please ensure it contains\n",
        "        # same the amount as defined in `self.nr_types` . ID 0 is preserved\n",
        "        # for background so please don't use it as ID\n",
        "        self.nuclei_type_dict = {\n",
        "            'Miscellaneous': 1, # ! Please ensure the matching ID is unique\n",
        "            'Inflammatory' : 2,\n",
        "            'Epithelial'   : 3,\n",
        "            'Spindle'      : 4,\n",
        "        }\n",
        "        assert len(self.nuclei_type_dict.values()) == self.nr_types - 1\n",
        "\n",
        "        #### Dynamically setting the config file into variable\n",
        "        #if mode == 'hover':\n",
        "        ##   config_file = importlib.import_module('opt.hover') # np_hv, np_dist\n",
        "        #else:\n",
        "        # #   config_file = importlib.import_module('opt.other') # fcn8, dcan, etc.\n",
        "       # config_dict = config_file.__getattribute__(self.model_type)\n",
        "\n",
        "        for variable, value in config_dict.items():\n",
        "            self.__setattr__(variable, value)\n",
        "        #### Training data\n",
        "\n",
        "        # patches are stored as numpy arrays with N channels\n",
        "        # ordering as [Image][Nuclei Pixels][Nuclei Type][Additional Map]\n",
        "        # Ex: with type_classification=True\n",
        "        #     HoVer-Net: RGB - Nuclei Pixels - Type Map - Horizontal and Vertical Map\n",
        "        # Ex: with type_classification=False\n",
        "        #     Dist     : RGB - Nuclei Pixels - Distance Map\n",
        "        data_code_dict = {\n",
        "            'unet'     : '536x536_84x84',\n",
        "            'dist'     : '536x536_84x84',\n",
        "            'fcn8'     : '512x512_256x256',\n",
        "            'dcan'     : '512x512_256x256',\n",
        "            'segnet'   : '512x512_256x256',\n",
        "            'micronet' : '504x504_252x252', \n",
        "            'np_hv'    : '540x540_80x80',\n",
        "            'np_dist'  : '540x540_80x80',\n",
        "        }\n",
        "\n",
        "        self.data_ext = '.npy' \n",
        "        # list of directories containing validation patches. \n",
        "        # For both train and valid directories, a comma separated list of directories can be used\n",
        "        self.train_dir = [train_files_path  % data_code_dict[self.model_type]]\n",
        "        self.valid_dir = [test_files_path % data_code_dict[self.model_type]]\n",
        "\n",
        "        # number of processes for parallel processing input\n",
        "        self.nr_procs_train = 8 \n",
        "        self.nr_procs_valid = 4 \n",
        "\n",
        "        self.input_norm  = True # normalize RGB to 0-1 range\n",
        "\n",
        "        ####\n",
        "        exp_id = 'v1.0/'\n",
        "        model_id = '%s' % self.model_type\n",
        "        self.model_name = '%s/%s' % (exp_id, model_id)\n",
        "        # loading chkpts in tensorflow, the path must not contain extra '/'\n",
        "        self.log_path = '/media/vqdang/logs/' # log root path - modify according to needs\n",
        "        self.save_dir = '%s/%s' % (self.log_path, self.model_name) # log file destination\n",
        "\n",
        "        #### Info for running inference\n",
        "        self.inf_auto_find_chkpt = True \n",
        "        # path to checkpoints will be used for inference, replace accordingly\n",
        "        self.inf_model_path  = self.save_dir + '/model-19640.index'\n",
        "\n",
        "        # output will have channel ordering as [Nuclei Type][Nuclei Pixels][Additional]\n",
        "        # where [Nuclei Type] will be used for getting the type of each instance\n",
        "        # while [Nuclei Pixels][Additional] will be used for extracting instances\n",
        "\n",
        "        self.inf_imgs_ext = '.png'\n",
        "        self.inf_data_dir = '../../../data/CoNSeP/test/Images/'\n",
        "        self.inf_output_dir = 'output/%s/%s/' % (exp_id, model_id)\n",
        "\n",
        "        # for inference during evalutaion mode i.e run by infer.py\n",
        "        self.eval_inf_input_tensor_names = ['images']\n",
        "        self.eval_inf_output_tensor_names = ['predmap-coded']\n",
        "        # for inference during training mode i.e run by trainer.py\n",
        "        self.train_inf_output_tensor_names = ['predmap-coded', 'truemap-coded']\n",
        "\n",
        "    def get_model(self):\n",
        "        if self.model_type == 'np_hv':\n",
        "            model_constructor = importlib.import_module('model.graph')\n",
        "            model_constructor = model_constructor.Model_NP_HV \n",
        "        elif self.model_type == 'np_dist':\n",
        "            model_constructor = importlib.import_module('model.graph')\n",
        "            model_constructor = model_constructor.Model_NP_DIST \n",
        "        else:\n",
        "            model_constructor = importlib.import_module('model.%s' % self.model_type)\n",
        "            model_constructor = model_constructor.Graph       \n",
        "        return model_constructor # NOTE return alias, not object\n",
        "\n",
        "    # refer to https://tensorpack.readthedocs.io/modules/dataflow.imgaug.html for \n",
        "    # information on how to modify the augmentation parameters\n",
        "    def get_train_augmentors(self, input_shape, output_shape, view=False):\n",
        "        print(input_shape, output_shape)\n",
        "        shape_augs = [\n",
        "            imgaug.Affine(\n",
        "                        shear=5, # in degree\n",
        "                        scale=(0.8, 1.2),\n",
        "                        rotate_max_deg=179,\n",
        "                        translate_frac=(0.01, 0.01),\n",
        "                        interp=cv2.INTER_NEAREST,\n",
        "                        border=cv2.BORDER_CONSTANT),\n",
        "            imgaug.Flip(vert=True),\n",
        "            imgaug.Flip(horiz=True),\n",
        "            imgaug.CenterCrop(input_shape),\n",
        "        ]\n",
        "\n",
        "        input_augs = [\n",
        "            imgaug.RandomApplyAug(\n",
        "                imgaug.RandomChooseAug(\n",
        "                    [\n",
        "                    GaussianBlur(),\n",
        "                    MedianBlur(),\n",
        "                    imgaug.GaussianNoise(),\n",
        "                    ]\n",
        "                ), 0.5),\n",
        "            # standard color augmentation\n",
        "            imgaug.RandomOrderAug(\n",
        "                [imgaug.Hue((-8, 8), rgb=True), \n",
        "                imgaug.Saturation(0.2, rgb=True),\n",
        "                imgaug.Brightness(26, clip=True),  \n",
        "                imgaug.Contrast((0.75, 1.25), clip=True),\n",
        "                ]),\n",
        "            imgaug.ToUint8(),\n",
        "        ]\n",
        "\n",
        "        label_augs = []\n",
        "        if self.model_type == 'unet' or self.model_type == 'micronet':\n",
        "            label_augs =[GenInstanceUnetMap(crop_shape=output_shape)]\n",
        "        if self.model_type == 'dcan':\n",
        "            label_augs =[GenInstanceContourMap(crop_shape=output_shape)]\n",
        "        if self.model_type == 'dist':\n",
        "            label_augs = [GenInstanceDistance(crop_shape=output_shape, inst_norm=False)]\n",
        "        if self.model_type == 'np_hv':\n",
        "            label_augs = [GenInstanceHV(crop_shape=output_shape)]\n",
        "        if self.model_type == 'np_dist':\n",
        "            label_augs = [GenInstanceDistance(crop_shape=output_shape, inst_norm=True)]\n",
        "\n",
        "        if not self.type_classification:            \n",
        "            label_augs.append(BinarizeLabel())\n",
        "\n",
        "        if not view:\n",
        "            label_augs.append(imgaug.CenterCrop(output_shape))        \n",
        "\n",
        "        return shape_augs, input_augs, label_augs\n",
        "\n",
        "    def get_valid_augmentors(self, input_shape, output_shape, view=False):\n",
        "        print(input_shape, output_shape)\n",
        "        shape_augs = [\n",
        "            imgaug.CenterCrop(input_shape),\n",
        "        ]\n",
        "\n",
        "        input_augs = None\n",
        "\n",
        "        label_augs = []\n",
        "        if self.model_type == 'unet' or self.model_type == 'micronet':\n",
        "            label_augs =[GenInstanceUnetMap(crop_shape=output_shape)]\n",
        "        if self.model_type == 'dcan':\n",
        "            label_augs =[GenInstanceContourMap(crop_shape=output_shape)]\n",
        "        if self.model_type == 'dist':\n",
        "            label_augs = [GenInstanceDistance(crop_shape=output_shape, inst_norm=False)]\n",
        "        if self.model_type == 'np_hv':\n",
        "            label_augs = [GenInstanceHV(crop_shape=output_shape)]\n",
        "        if self.model_type == 'np_dist':\n",
        "            label_augs = [GenInstanceDistance(crop_shape=output_shape, inst_norm=True)]\n",
        "        label_augs.append(BinarizeLabel())\n",
        "\n",
        "        if not view:\n",
        "            label_augs.append(imgaug.CenterCrop(output_shape))        \n",
        "\n",
        "        return shape_augs, input_augs, label_augs"
      ],
      "metadata": {
        "id": "DFyGvKwwgrgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model"
      ],
      "metadata": {
        "id": "0r7c1wTcdXXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "####\n",
        "def upsample2x(name, x):\n",
        "    \"\"\"\n",
        "    Nearest neighbor up-sampling\n",
        "    \"\"\"\n",
        "    return FixedUnPooling(\n",
        "                name, x, 2, unpool_mat=np.ones((2, 2), dtype='float32'),\n",
        "                data_format='channels_first')\n",
        "####\n",
        "def res_blk(name, l, ch, ksize, count, split=1, strides=1, freeze=False):\n",
        "    ch_in = l.get_shape().as_list()\n",
        "    with tf.variable_scope(name):\n",
        "        for i in range(0, count):\n",
        "            with tf.variable_scope('block' + str(i)):  \n",
        "                x = l if i == 0 else BNReLU('preact', l)\n",
        "                x = Conv2D('conv1', x, ch[0], ksize[0], activation=BNReLU)\n",
        "                x = Conv2D('conv2', x, ch[1], ksize[1], split=split, \n",
        "                                strides=strides if i == 0 else 1, activation=BNReLU)\n",
        "                x = Conv2D('conv3', x, ch[2], ksize[2], activation=tf.identity)\n",
        "                if (strides != 1 or ch_in[1] != ch[2]) and i == 0:\n",
        "                    l = Conv2D('convshortcut', l, ch[2], 1, strides=strides)\n",
        "                x = tf.stop_gradient(x) if freeze else x\n",
        "                l = l + x\n",
        "        # end of each group need an extra activation\n",
        "        l = BNReLU('bnlast',l)  \n",
        "    return l\n",
        "####\n",
        "def dense_blk(name, l, ch, ksize, count, split=1, padding='valid'):\n",
        "    with tf.variable_scope(name):\n",
        "        for i in range(0, count):\n",
        "            with tf.variable_scope('blk/' + str(i)):\n",
        "                x = BNReLU('preact_bna', l)\n",
        "                x = Conv2D('conv1', x, ch[0], ksize[0], padding=padding, activation=BNReLU)\n",
        "                x = Conv2D('conv2', x, ch[1], ksize[1], padding=padding, split=split)\n",
        "                ##\n",
        "                if padding == 'valid':\n",
        "                    x_shape = x.get_shape().as_list()\n",
        "                    l_shape = l.get_shape().as_list()\n",
        "                    l = crop_op(l, (l_shape[2] - x_shape[2], \n",
        "                                    l_shape[3] - x_shape[3]))\n",
        "\n",
        "                l = tf.concat([l, x], axis=1)\n",
        "        l = BNReLU('blk_bna', l)\n",
        "    return l\n",
        "####\n",
        "def encoder(i, freeze):\n",
        "    \"\"\"\n",
        "    Pre-activated ResNet50 Encoder\n",
        "    \"\"\"\n",
        "\n",
        "    d1 = Conv2D('conv0',  i, 64, 7, padding='valid', strides=1, activation=BNReLU)\n",
        "    d1 = res_blk('group0', d1, [ 64,  64,  256], [1, 3, 1], 3, strides=1, freeze=freeze)                       \n",
        "    \n",
        "    d2 = res_blk('group1', d1, [128, 128,  512], [1, 3, 1], 4, strides=2, freeze=freeze)\n",
        "    d2 = tf.stop_gradient(d2) if freeze else d2\n",
        "\n",
        "    d3 = res_blk('group2', d2, [256, 256, 1024], [1, 3, 1], 6, strides=2, freeze=freeze)\n",
        "    d3 = tf.stop_gradient(d3) if freeze else d3\n",
        "\n",
        "    d4 = res_blk('group3', d3, [512, 512, 2048], [1, 3, 1], 3, strides=2, freeze=freeze)\n",
        "    d4 = tf.stop_gradient(d4) if freeze else d4\n",
        "    \n",
        "    d4 = Conv2D('conv_bot',  d4, 1024, 1, padding='same')\n",
        "    return [d1, d2, d3, d4]\n",
        "####\n",
        "def decoder(name, i):\n",
        "    pad = 'valid' # to prevent boundary artifacts\n",
        "    with tf.variable_scope(name):\n",
        "        with tf.variable_scope('u3'):\n",
        "            u3 = upsample2x('rz', i[-1])\n",
        "            u3_sum = tf.add_n([u3, i[-2]])\n",
        "\n",
        "            u3 = Conv2D('conva', u3_sum, 256, 5, strides=1, padding=pad)   \n",
        "            u3 = dense_blk('dense', u3, [128, 32], [1, 5], 8, split=4, padding=pad)\n",
        "            u3 = Conv2D('convf', u3, 512, 1, strides=1)   \n",
        "        ####\n",
        "        with tf.variable_scope('u2'):          \n",
        "            u2 = upsample2x('rz', u3)\n",
        "            u2_sum = tf.add_n([u2, i[-3]])\n",
        "\n",
        "            u2x = Conv2D('conva', u2_sum, 128, 5, strides=1, padding=pad)\n",
        "            u2 = dense_blk('dense', u2x, [128, 32], [1, 5], 4, split=4, padding=pad)\n",
        "            u2 = Conv2D('convf', u2, 256, 1, strides=1)   \n",
        "        ####\n",
        "        with tf.variable_scope('u1'):          \n",
        "            u1 = upsample2x('rz', u2)\n",
        "            u1_sum = tf.add_n([u1, i[-4]])\n",
        "\n",
        "            u1 = Conv2D('conva', u1_sum, 64, 5, strides=1, padding='same')\n",
        "\n",
        "    return [u3, u2x, u1]\n",
        "\n",
        "####\n",
        "class Model(ModelDesc, Config):\n",
        "    def __init__(self, freeze=False):\n",
        "        super(Model, self).__init__()\n",
        "        assert tf.test.is_gpu_available()\n",
        "        self.freeze = freeze\n",
        "        self.data_format = 'NCHW'\n",
        "\n",
        "    def _get_inputs(self):\n",
        "        return [InputDesc(tf.float32, [None] + self.train_input_shape + [3], 'images'),\n",
        "                InputDesc(tf.float32, [None] + self.train_mask_shape  + [None], 'truemap-coded')]\n",
        "    \n",
        "    # for node to receive manual info such as learning rate.\n",
        "    def add_manual_variable(self, name, init_value, summary=True):\n",
        "        var = tf.get_variable(name, initializer=init_value, trainable=False)\n",
        "        if summary:\n",
        "            tf.summary.scalar(name + '-summary', var)\n",
        "        return\n",
        "\n",
        "    def _get_optimizer(self):\n",
        "        with tf.variable_scope(\"\", reuse=True):\n",
        "            lr = tf.get_variable('learning_rate')\n",
        "        opt = self.optimizer(learning_rate=lr)\n",
        "        return opt\n",
        "\n",
        "####\n",
        "class Model_NP_HV(Model):\n",
        "    def _build_graph(self, inputs):\n",
        "        \n",
        "        images, truemap_coded = inputs\n",
        "        orig_imgs = images\n",
        "        if hasattr(self, 'type_classification') and self.type_classification:\n",
        "            true_type = truemap_coded[...,1]\n",
        "            true_type = tf.cast(true_type, tf.int32)\n",
        "            true_type = tf.identity(true_type, name='truemap-type')\n",
        "            one_type  = tf.one_hot(true_type, self.nr_types, axis=-1)\n",
        "            true_type = tf.expand_dims(true_type, axis=-1)\n",
        "\n",
        "            true_np = tf.cast(true_type > 0, tf.int32) # ? sanity this\n",
        "            true_np = tf.identity(true_np, name='truemap-np')\n",
        "            one_np  = tf.one_hot(tf.squeeze(true_np), 2, axis=-1)\n",
        "        else:\n",
        "            true_np = truemap_coded[...,0]\n",
        "            true_np = tf.cast(true_np, tf.int32)\n",
        "            true_np = tf.identity(true_np, name='truemap-np')\n",
        "            one_np  = tf.one_hot(true_np, 2, axis=-1)\n",
        "            true_np = tf.expand_dims(true_np, axis=-1)\n",
        "\n",
        "        true_hv = truemap_coded[...,-2:]\n",
        "        true_hv = tf.identity(true_hv, name='truemap-hv')\n",
        "\n",
        "        ####\n",
        "        with argscope(Conv2D, activation=tf.identity, use_bias=False, # K.he initializer\n",
        "                      W_init=tf.variance_scaling_initializer(scale=2.0, mode='fan_out')), \\\n",
        "                argscope([Conv2D, BatchNorm], data_format=self.data_format):\n",
        "\n",
        "            i = tf.transpose(images, [0, 3, 1, 2])\n",
        "            i = i if not self.input_norm else i / 255.0\n",
        "\n",
        "            ####\n",
        "            d = encoder(i, False)\n",
        "            d[0] = crop_op(d[0], (184, 184))\n",
        "            d[1] = crop_op(d[1], (72, 72))\n",
        "\n",
        "            ####\n",
        "            np_feat = decoder('np', d)\n",
        "            npx = BNReLU('preact_out_np', np_feat[-1])\n",
        "\n",
        "            hv_feat = decoder('hv', d)\n",
        "            hv = BNReLU('preact_out_hv', hv_feat[-1])\n",
        "\n",
        "            if self.type_classification:\n",
        "                tp_feat = decoder('tp', d)\n",
        "                tp = BNReLU('preact_out_tp', tp_feat[-1])\n",
        "\n",
        "                # Nuclei Type Pixels (TP)\n",
        "                logi_class = Conv2D('conv_out_tp', tp, self.nr_types, 1, use_bias=True, activation=tf.identity)\n",
        "                logi_class = tf.transpose(logi_class, [0, 2, 3, 1])\n",
        "                soft_class = tf.nn.softmax(logi_class, axis=-1)\n",
        "\n",
        "            #### Nuclei Pixels (NP)\n",
        "            logi_np = Conv2D('conv_out_np', npx, 2, 1, use_bias=True, activation=tf.identity)\n",
        "            logi_np = tf.transpose(logi_np, [0, 2, 3, 1])\n",
        "            soft_np = tf.nn.softmax(logi_np, axis=-1)\n",
        "            prob_np = tf.identity(soft_np[...,1], name='predmap-prob-np')\n",
        "            prob_np = tf.expand_dims(prob_np, axis=-1)\n",
        "\n",
        "            #### Horizontal-Vertival (HV)\n",
        "            logi_hv = Conv2D('conv_out_hv', hv, 2, 1, use_bias=True, activation=tf.identity)\n",
        "            logi_hv = tf.transpose(logi_hv, [0, 2, 3, 1])\n",
        "            prob_hv = tf.identity(logi_hv, name='predmap-prob-hv')\n",
        "            pred_hv = tf.identity(logi_hv, name='predmap-hv')\n",
        "    \n",
        "            # * channel ordering: type-map, segmentation map\n",
        "            # encoded so that inference can extract all output at once\n",
        "            if self.type_classification:\n",
        "                predmap_coded = tf.concat([soft_class, prob_np, pred_hv], axis=-1, name='predmap-coded')\n",
        "            else:\n",
        "                predmap_coded = tf.concat([prob_np, pred_hv], axis=-1, name='predmap-coded')\n",
        "        ####\n",
        "        def get_gradient_hv(l, h_ch, v_ch):\n",
        "            \"\"\"\n",
        "            Calculate the horizontal partial differentiation for horizontal channel\n",
        "            and the vertical partial differentiation for vertical channel.\n",
        "            The partial differentiation is approximated by calculating the central differnce\n",
        "            which is obtained by using Sobel kernel of size 5x5. The boundary is zero-padded\n",
        "            when channel is convolved with the Sobel kernel.\n",
        "            Args:\n",
        "                l (tensor): tensor of shape NHWC with C should be 2 (1 channel for horizonal \n",
        "                            and 1 channel for vertical)\n",
        "                h_ch(int) : index within C axis of `l` that corresponds to horizontal channel\n",
        "                v_ch(int) : index within C axis of `l` that corresponds to vertical channel\n",
        "            \"\"\"\n",
        "            def get_sobel_kernel(size):\n",
        "                assert size % 2 == 1, 'Must be odd, get size=%d' % size\n",
        "\n",
        "                h_range = np.arange(-size//2+1, size//2+1, dtype=np.float32)\n",
        "                v_range = np.arange(-size//2+1, size//2+1, dtype=np.float32)\n",
        "                h, v = np.meshgrid(h_range, v_range)\n",
        "                kernel_h = h / (h * h + v * v + 1.0e-15)\n",
        "                kernel_v = v / (h * h + v * v + 1.0e-15)\n",
        "                return kernel_h, kernel_v            \n",
        "\n",
        "            mh, mv = get_sobel_kernel(5)\n",
        "            mh = tf.constant(mh, dtype=tf.float32)\n",
        "            mv = tf.constant(mv, dtype=tf.float32)\n",
        "\n",
        "            mh = tf.reshape(mh, [5, 5, 1, 1])\n",
        "            mv = tf.reshape(mv, [5, 5, 1, 1])\n",
        "            \n",
        "            # central difference to get gradient, ignore the boundary problem  \n",
        "            h = tf.expand_dims(l[...,h_ch], axis=-1)  \n",
        "            v = tf.expand_dims(l[...,v_ch], axis=-1)  \n",
        "            dh = tf.nn.conv2d(h, mh, strides=[1, 1, 1, 1], padding='SAME')\n",
        "            dv = tf.nn.conv2d(v, mv, strides=[1, 1, 1, 1], padding='SAME')\n",
        "            output = tf.concat([dh, dv], axis=-1)\n",
        "            return output\n",
        "        def loss_mse(true, pred, name=None):\n",
        "            ### regression loss\n",
        "            loss = pred - true\n",
        "            loss = tf.reduce_mean(loss * loss, name=name)\n",
        "            return loss\n",
        "        def loss_msge(true, pred, focus, name=None):\n",
        "            focus = tf.stack([focus, focus], axis=-1)\n",
        "            pred_grad = get_gradient_hv(pred, 1, 0)\n",
        "            true_grad = get_gradient_hv(true, 1, 0) \n",
        "            loss = pred_grad - true_grad\n",
        "            loss = focus * (loss * loss)\n",
        "            # artificial reduce_mean with focus region\n",
        "            loss = tf.reduce_sum(loss) / (tf.reduce_sum(focus) + 1.0e-8)\n",
        "            loss = tf.identity(loss, name=name)\n",
        "            return loss\n",
        "\n",
        "        ####\n",
        "        if get_current_tower_context().is_training:\n",
        "            #---- LOSS ----#\n",
        "            loss = 0\n",
        "            for term, weight in self.loss_term.items():\n",
        "                if term == 'mse':\n",
        "                    term_loss = loss_mse(true_hv, pred_hv, name='loss-mse')\n",
        "                elif term == 'msge':\n",
        "                    focus = truemap_coded[...,0]\n",
        "                    term_loss = loss_msge(true_hv, pred_hv, focus, name='loss-msge')\n",
        "                elif term == 'bce':\n",
        "                    term_loss = categorical_crossentropy(soft_np, one_np)\n",
        "                    term_loss = tf.reduce_mean(term_loss, name='loss-bce')\n",
        "                elif 'dice' in self.loss_term:\n",
        "                    term_loss = dice_loss(soft_np[...,0], one_np[...,0]) \\\n",
        "                              + dice_loss(soft_np[...,1], one_np[...,1])\n",
        "                    term_loss = tf.identity(term_loss, name='loss-dice')\n",
        "                else:\n",
        "                    assert False, 'Not support loss term: %s' % term\n",
        "                add_moving_summary(term_loss)\n",
        "                loss += term_loss * weight\n",
        "\n",
        "            if self.type_classification:\n",
        "                term_loss = categorical_crossentropy(soft_class, one_type)\n",
        "                term_loss = tf.reduce_mean(term_loss, name='loss-xentropy-class')\n",
        "                add_moving_summary(term_loss)\n",
        "                loss = loss + term_loss\n",
        "\n",
        "                term_loss = 0\n",
        "                for type_id in range(self.nr_types):\n",
        "                    term_loss += dice_loss(soft_class[...,type_id], \n",
        "                                           one_type[...,type_id])\n",
        "                term_loss = tf.identity(term_loss, name='loss-dice-class')\n",
        "                add_moving_summary(term_loss)\n",
        "                loss = loss + term_loss\n",
        "\n",
        "            ### combine the loss into single cost function\n",
        "            self.cost = tf.identity(loss, name='overall-loss')            \n",
        "            add_moving_summary(self.cost)\n",
        "            ####\n",
        "\n",
        "            add_param_summary(('.*/W', ['histogram']))   # monitor W\n",
        "\n",
        "            ### logging visual sthg\n",
        "            orig_imgs = tf.cast(orig_imgs  , tf.uint8)\n",
        "            tf.summary.image('input', orig_imgs, max_outputs=1)\n",
        "\n",
        "            orig_imgs = crop_op(orig_imgs, (190, 190), \"NHWC\")\n",
        "\n",
        "            pred_np = colorize(prob_np[...,0], cmap='jet')\n",
        "            true_np = colorize(true_np[...,0], cmap='jet')\n",
        "            \n",
        "            pred_h = colorize(prob_hv[...,0], vmin=-1, vmax=1, cmap='jet')\n",
        "            pred_v = colorize(prob_hv[...,1], vmin=-1, vmax=1, cmap='jet')\n",
        "            true_h = colorize(true_hv[...,0], vmin=-1, vmax=1, cmap='jet')\n",
        "            true_v = colorize(true_hv[...,1], vmin=-1, vmax=1, cmap='jet')\n",
        "\n",
        "            if not self.type_classification:\n",
        "                viz = tf.concat([orig_imgs, \n",
        "                                pred_h, pred_v, pred_np, \n",
        "                                true_h, true_v, true_np], 2)\n",
        "            else:\n",
        "                pred_type = tf.transpose(soft_class, (0, 1, 3, 2))\n",
        "                pred_type = tf.reshape(pred_type, [-1, 80, 80 * self.nr_types])\n",
        "                true_type = tf.cast(true_type[...,0] / self.nr_classes, tf.float32)\n",
        "                true_type = colorize(true_type, vmin=0, vmax=1, cmap='jet')\n",
        "                pred_type = colorize(pred_type, vmin=0, vmax=1, cmap='jet')\n",
        "\n",
        "                viz = tf.concat([orig_imgs, \n",
        "                                pred_h, pred_v, pred_np, pred_type, \n",
        "                                true_h, true_v, true_np, true_type,], 2)\n",
        "\n",
        "            viz = tf.concat([viz[0], viz[-1]], axis=0)\n",
        "            viz = tf.expand_dims(viz, axis=0)\n",
        "            tf.summary.image('output', viz, max_outputs=1)\n",
        "\n",
        "        return\n",
        "####\n",
        "\n",
        "class Model_NP_DIST(Model):\n",
        "    def _build_graph(self, inputs):\n",
        "       \n",
        "        images, truemap_coded = inputs\n",
        "\n",
        "        orig_imgs = images\n",
        "\n",
        "        true_np = truemap_coded[...,0]\n",
        "        true_np = tf.cast(true_np, tf.int32)\n",
        "        true_np = tf.identity(true_np, name='truemap-np')\n",
        "        one_np  = tf.one_hot(true_np, 2, axis=-1)\n",
        "        true_np = tf.expand_dims(true_np, axis=-1)\n",
        "\n",
        "        true_dist = truemap_coded[...,1:]\n",
        "        true_dist = tf.identity(true_dist, name='truemap-dist')\n",
        "\n",
        "        ####\n",
        "        with argscope(Conv2D, activation=tf.identity, use_bias=False, # K.he initializer\n",
        "                      W_init=tf.variance_scaling_initializer(scale=2.0, mode='fan_out')), \\\n",
        "                argscope([Conv2D, BatchNorm], data_format=self.data_format):\n",
        "\n",
        "            i = tf.transpose(images, [0, 3, 1, 2])\n",
        "            i = i if not self.input_norm else i / 255.0\n",
        "\n",
        "            ####\n",
        "            d = encoder(i, self.freeze)\n",
        "            d[0] = crop_op(d[0], (184, 184))\n",
        "            d[1] = crop_op(d[1], (72, 72))\n",
        "\n",
        "            ####\n",
        "            np_feat = decoder('np', d)\n",
        "            np = BNReLU('preact_out_np', np_feat[-1])\n",
        "\n",
        "            dist_feat = decoder('dst', d)\n",
        "            dist = BNReLU('preact_out_dist', dist_feat[-1])\n",
        "\n",
        "            ####\n",
        "            logi_np = Conv2D('conv_out_np', np, 2, 1, use_bias=True, activation=tf.identity)\n",
        "            logi_np = tf.transpose(logi_np, [0, 2, 3, 1])\n",
        "            soft_np = tf.nn.softmax(logi_np, axis=-1)\n",
        "            prob_np = tf.identity(soft_np[...,1], name='predmap-prob-np')\n",
        "            prob_np = tf.expand_dims(prob_np, axis=-1)\n",
        "            pred_np = tf.argmax(soft_np, axis=-1, name='predmap-np')\n",
        "            pred_np = tf.expand_dims(tf.cast(pred_np, tf.float32), axis=-1)\n",
        "\n",
        "            ####\n",
        "            logi_dist = Conv2D('conv_out_dist', dist, 1, 1, use_bias=True, activation=tf.identity)\n",
        "            logi_dist = tf.transpose(logi_dist, [0, 2, 3, 1])\n",
        "            prob_dist = tf.identity(logi_dist, name='predmap-prob-dist')\n",
        "            pred_dist = tf.identity(logi_dist, name='predmap-dist')\n",
        "\n",
        "            # encoded so that inference can extract all output at once\n",
        "            predmap_coded = tf.concat([prob_np, pred_dist], axis=-1, name='predmap-coded')\n",
        "        ####\n",
        "\n",
        "        ####\n",
        "        if get_current_tower_context().is_training:\n",
        "            ######## LOSS\n",
        "            ### Distance regression loss\n",
        "            loss_mse = pred_dist - true_dist\n",
        "            loss_mse = loss_mse * loss_mse\n",
        "            loss_mse = tf.reduce_mean(loss_mse, name='loss-mse')\n",
        "            add_moving_summary(loss_mse)   \n",
        "\n",
        "            ### Nuclei Blob classification loss\n",
        "            loss_bce = categorical_crossentropy(soft_np, one_np)\n",
        "            loss_bce = tf.reduce_mean(loss_bce, name='loss-bce')\n",
        "            add_moving_summary(loss_bce)\n",
        "\n",
        "            ### combine the loss into single cost function\n",
        "            self.cost = tf.identity(loss_mse + loss_bce, name='overall-loss')            \n",
        "            add_moving_summary(self.cost)\n",
        "            ####\n",
        "\n",
        "            add_param_summary(('.*/W', ['histogram']))   # monitor W\n",
        "\n",
        "            #### logging visual sthg\n",
        "            orig_imgs = tf.cast(orig_imgs  , tf.uint8)\n",
        "            tf.summary.image('input', orig_imgs, max_outputs=1)\n",
        "\n",
        "            orig_imgs = crop_op(orig_imgs, (190, 190), \"NHWC\")\n",
        "\n",
        "            pred_np = colorize(prob_np[...,0], cmap='jet')\n",
        "            true_np = colorize(true_np[...,0], cmap='jet')\n",
        "\n",
        "            pred_dist = colorize(prob_dist[...,0], cmap='jet')\n",
        "            true_dist = colorize(true_dist[...,0], cmap='jet')\n",
        "\n",
        "            viz = tf.concat([orig_imgs, \n",
        "                            true_np, pred_np, \n",
        "                            true_dist, pred_dist,], 2)\n",
        "\n",
        "            tf.summary.image('output', viz, max_outputs=1)\n",
        "\n",
        "        return"
      ],
      "metadata": {
        "id": "RQFHXDc2dW6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "RB-E953RdZvI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StatCollector(Inferencer, Config):\n",
        "    \"\"\"\n",
        "    Accumulate output of inference during training.\n",
        "    After the inference finishes, calculate the statistics\n",
        "    \"\"\"\n",
        "    def __init__(self, prefix='valid'):\n",
        "        super(StatCollector, self).__init__()\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def _get_fetches(self):\n",
        "        return self.train_inf_output_tensor_names\n",
        "\n",
        "    def _before_inference(self):\n",
        "        self.true_list = []\n",
        "        self.pred_list = []\n",
        "\n",
        "    def _on_fetches(self, outputs):\n",
        "        pred, true = outputs\n",
        "        self.true_list.extend(true)\n",
        "        self.pred_list.extend(pred)\n",
        " \n",
        "    def _after_inference(self):\n",
        "        # ! factor this out\n",
        "        def _dice(true, pred, label):\n",
        "            true = np.array(true == label, np.int32)            \n",
        "            pred = np.array(pred == label, np.int32)            \n",
        "            inter = (pred * true).sum()\n",
        "            total = (pred + true).sum()\n",
        "            return 2 * inter /  (total + 1.0e-8)\n",
        "\n",
        "        stat_dict = {}\n",
        "        pred = np.array(self.pred_list)\n",
        "        true = np.array(self.true_list)\n",
        "\n",
        "        # have to get total number pixels for mean per pixel\n",
        "        nr_pixels = np.size(true[...,:1])\n",
        "\n",
        "        if self.type_classification: \n",
        "         \n",
        "            pred_type = pred[...,:self.nr_types]\n",
        "            pred_inst = pred[...,self.nr_types:]\n",
        "\n",
        "            true_inst = true\n",
        "            true_type = true[...,1]\n",
        "            true_np = (true_type > 0).astype('int32')\n",
        "           \n",
        "        else:\n",
        "            pred_inst = pred\n",
        "            true_inst = true\n",
        "            true_np = true[...,0]\n",
        "\n",
        "        # * index selection followed what is defined in the graph\n",
        "        # * and all model's graphs must follow same index ordering protocol\n",
        "\n",
        "        # classification statistic\n",
        "        if self.model_type == 'dist':\n",
        "            # regression\n",
        "            pred_dst = pred_inst[...,-1]\n",
        "            true_dst = true_inst[...,-1]\n",
        "            error = pred_dst - true_dst\n",
        "            mse = np.sum(error * error) / nr_pixels\n",
        "            stat_dict[self.prefix + '_mse'] = mse\n",
        "        elif self.model_type == 'np_hv':\n",
        "            pred_hv = pred_inst[...,-2:]\n",
        "            true_hv = true_inst[...,-2:]\n",
        "            error = pred_hv - true_hv\n",
        "            mse = np.sum(error * error) / nr_pixels\n",
        "            stat_dict[self.prefix + '_mse'] = mse\n",
        "\n",
        "        # classification statistic\n",
        "        if self.model_type != 'dist':\n",
        "            pred_np = pred_inst[...,0]\n",
        "            true_np = true_inst[...,0]\n",
        "\n",
        "            pred_np[pred_np >  0.5] = 1.0\n",
        "            pred_np[pred_np <= 0.5] = 0.0\n",
        "\n",
        "            accuracy = (pred_np == true_np).sum() / nr_pixels\n",
        "            inter = (pred_np * true_np).sum()\n",
        "            total = (pred_np + true_np).sum()\n",
        "            dice = 2 * inter / (total + 1.0e-8)\n",
        "\n",
        "            stat_dict[self.prefix + '_acc' ] = accuracy\n",
        "            stat_dict[self.prefix + '_dice'] = dice\n",
        "\n",
        "            if self.model_type == 'dcan':\n",
        "                # do one more for contour\n",
        "                pred_np = pred_inst[...,1]\n",
        "                true_np = true_inst[...,1]\n",
        "                pred_np[pred_np >  0.5] = 1.0\n",
        "                pred_np[pred_np <= 0.5] = 0.0\n",
        "\n",
        "                inter = (pred_np * true_np).sum()\n",
        "                total = (pred_np + true_np).sum()\n",
        "                dice = 2 * inter / (total + 1.0e-8)\n",
        "\n",
        "                stat_dict[self.prefix + '_cnt_dice'] = dice\n",
        "\n",
        "        if self.type_classification:\n",
        "            pred_type = np.argmax(pred_type, axis=-1)\n",
        "\n",
        "            type_dict = self.nuclei_type_dict\n",
        "            type_dice_list = []\n",
        "            for type_name, type_id in type_dict.items():\n",
        "                dice_val = _dice(true_type, pred_type, type_id)\n",
        "                type_dice_list.append(dice_val)\n",
        "                stat_dict['%s_dice_%s' % (self.prefix, type_name)] = dice_val\n",
        "\n",
        "        return stat_dict\n",
        "####\n",
        "\n",
        "###########################################\n",
        "class Trainer(Config):   \n",
        "    ####\n",
        "    def get_datagen(self, batch_size, mode='train', view=False):\n",
        "        if mode == 'train':\n",
        "            augmentors = self.get_train_augmentors(\n",
        "                                            self.train_input_shape,\n",
        "                                            self.train_mask_shape,\n",
        "                                            view)\n",
        "            data_files = get_files(self.train_dir, self.data_ext)\n",
        "            data_generator = loader.train_generator\n",
        "            nr_procs = self.nr_procs_train\n",
        "        else:\n",
        "            augmentors = self.get_valid_augmentors(\n",
        "                                            self.infer_input_shape,\n",
        "                                            self.infer_mask_shape,\n",
        "                                            view)\n",
        "            data_files = get_files(self.valid_dir, self.data_ext)\n",
        "            data_generator = loader.valid_generator\n",
        "            nr_procs = self.nr_procs_valid\n",
        "\n",
        "        # set nr_proc=1 for viewing to ensure clean ctrl-z\n",
        "        nr_procs = 1 if view else nr_procs\n",
        "        dataset = loader.DatasetSerial(data_files)\n",
        "        datagen = data_generator(dataset,\n",
        "                        shape_aug=augmentors[0],\n",
        "                        input_aug=augmentors[1],\n",
        "                        label_aug=augmentors[2],\n",
        "                        batch_size=batch_size,\n",
        "                        nr_procs=nr_procs)\n",
        "        \n",
        "        return datagen      \n",
        "    ####\n",
        "    def view_dataset(self, mode='train'):\n",
        "        assert mode == 'train' or mode == 'valid', \"Invalid view mode\"\n",
        "        datagen = self.get_datagen(4, mode=mode, view=True)\n",
        "        loader.visualize(datagen, 4)\n",
        "        return\n",
        "    ####\n",
        "    def run_once(self, opt, sess_init=None, save_dir=None):\n",
        "        ####\n",
        "        train_datagen = self.get_datagen(opt['train_batch_size'], mode='train')\n",
        "        valid_datagen = self.get_datagen(opt['infer_batch_size'], mode='valid')\n",
        "\n",
        "        ###### must be called before ModelSaver\n",
        "        if save_dir is None:\n",
        "            logger.set_logger_dir(self.save_dir)\n",
        "        else:\n",
        "            logger.set_logger_dir(save_dir)\n",
        "\n",
        "        ######            \n",
        "        model_flags = opt['model_flags']\n",
        "        model = self.get_model()(**model_flags)\n",
        "        ######\n",
        "        callbacks=[\n",
        "                ModelSaver(max_to_keep=opt['nr_epochs']),\n",
        "        ]\n",
        "\n",
        "        for param_name, param_info in opt['manual_parameters'].items():\n",
        "            model.add_manual_variable(param_name, param_info[0])\n",
        "            callbacks.append(ScheduledHyperParamSetter(param_name, param_info[1]))\n",
        "        # multi-GPU inference (with mandatory queue prefetch)\n",
        "        infs = [StatCollector()]\n",
        "        callbacks.append(DataParallelInferenceRunner(\n",
        "                                valid_datagen, infs, list(range(nr_gpus))))\n",
        "        callbacks.append(MaxSaver('valid_dice'))\n",
        "        \n",
        "        ######\n",
        "        steps_per_epoch = train_datagen.size() // nr_gpus\n",
        "\n",
        "        config = TrainConfig(\n",
        "                    model           = model,\n",
        "                    callbacks       = callbacks      ,\n",
        "                    dataflow        = train_datagen  ,\n",
        "                    steps_per_epoch = steps_per_epoch,\n",
        "                    max_epoch       = opt['nr_epochs'],\n",
        "                )\n",
        "        config.session_init = sess_init\n",
        "\n",
        "        launch_train_with_config(config, SyncMultiGPUTrainerParameterServer(nr_gpus))\n",
        "        tf.reset_default_graph() # remove the entire graph in case of multiple runs\n",
        "        return\n",
        "    ####\n",
        "    def run(self):\n",
        "        def get_last_chkpt_path(prev_phase_dir):\n",
        "            stat_file_path = prev_phase_dir + '/stats.json'\n",
        "            with open(stat_file_path) as stat_file:\n",
        "                info = json.load(stat_file)\n",
        "            chkpt_list = [epoch_stat['global_step'] for epoch_stat in info]\n",
        "            last_chkpts_path = \"%smodel-%d.index\" % (prev_phase_dir, max(chkpt_list))\n",
        "            return last_chkpts_path\n",
        "\n",
        "        phase_opts = self.training_phase\n",
        "\n",
        "        if len(phase_opts) > 1:\n",
        "            for idx, opt in enumerate(phase_opts):\n",
        "                random.seed(self.seed)\n",
        "                np.random.seed(self.seed)\n",
        "                tf.random.set_random_seed(self.seed)\n",
        "\n",
        "                log_dir = '%s/%02d/' % (self.save_dir, idx)\n",
        "                pretrained_path = opt['pretrained_path'] \n",
        "                if pretrained_path == -1:\n",
        "                    pretrained_path = get_last_chkpt_path(prev_log_dir)\n",
        "                    init_weights = SaverRestore(pretrained_path, ignore=['learning_rate'])\n",
        "                elif pretrained_path is not None:\n",
        "                    init_weights = get_model_loader(pretrained_path)\n",
        "                self.run_once(opt, sess_init=init_weights, save_dir=log_dir)\n",
        "                prev_log_dir = log_dir\n",
        "        else:\n",
        "            random.seed(self.seed)\n",
        "            np.random.seed(self.seed)\n",
        "            tf.random.set_random_seed(self.seed)\n",
        "\n",
        "            opt = phase_opts[0]\n",
        "            init_weights = None\n",
        "            if 'pretrained_path' in opt:\n",
        "                assert opt['pretrained_path'] != -1\n",
        "                init_weights = get_model_loader(opt['pretrained_path'])\n",
        "            self.run_once(opt, sess_init=init_weights, save_dir=self.save_dir)\n",
        "\n",
        "        return\n",
        "    ####\n",
        "####\n",
        "\n",
        "###########################################################################\n"
      ],
      "metadata": {
        "id": "GXr9NlsVdauv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here comes the actual training"
      ],
      "metadata": {
        "id": "MtHUo1FdhJAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--gpu', help=\"comma separated list of GPU(s) to use.\")\n",
        "parser.add_argument('--view', help=\"view dataset, received either 'train' or 'valid' as input\")\n",
        "args, unknown = parser.parse_known_args()\n",
        "\n",
        "trainer = Trainer()\n",
        "if args.view:\n",
        "    trainer.view_dataset(args.view)\n",
        "else:\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu #args.gpu returns 0, so think it is due to specifications in the host machine\n",
        "    nr_gpus = len(args.gpu.split(','))\n",
        "    trainer.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "R63DbrD2hIT4",
        "outputId": "f4de4b93-6bb7-407f-a0f1-386e6890f829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-5ee70b1010c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'CUDA_VISIBLE_DEVICES'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m \u001b[0;31m#None så det blir dåligt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mnr_gpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/os.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencodekey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencodevalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/os.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"str expected, not %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'surrogateescape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: str expected, not NoneType"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tb"
      ],
      "metadata": {
        "id": "TM4l-s5AdcCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n"
      ],
      "metadata": {
        "id": "qVryylKpdbjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "85LTD0pDm3iS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}